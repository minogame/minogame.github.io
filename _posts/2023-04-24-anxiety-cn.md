---
layout: post
title: 尝试为大家消除一些LLM带来的焦虑感
date: 2023-04-24 21:04:00
description: 蚂蚁海星 · 2023年04月24日 21:04 · 广东
tags: philosophy
disqus_comments: true
categories: Chinese
---

众所周知，LLM目前已经造成了极大的恐慌，反思潮与焦虑感。这几种状况，突出表现在无论是否依靠传播作为主业的（自）媒体，开始铺天盖地地传播ChatGPT的新闻/LLM的教程/业界的动态等等事物。与此同时，大致几百家国内的大中小法人实体（包括还没注册的），开始冒头把自己的赛道改换为对话式LLM或者将自己对标OpenAI。再与此同时，又有某直辖市行政组织发表了《人工智能产业发展白皮书》，提出了“支持头部企业打造对标ChatGPT的大模型” 的言论。当然最后最糟糕的，其实是那封Pause Giant AI Experiments的公开信，充分地传达出一种“你们不带我上车，那我干脆把路给你拆了”的怨气。

事实上，正如文章的title，我只愿意（也只能）努力帮大家消除一些焦虑感，而至于恐慌与反思，反倒是乐于看到的。或者说，我有充足理由来说明恐慌与反思是理性人应当做的，但是焦虑却不是。之所以我们认为LLM，或者更准确地说，OpenAI的GPT系列，给我们带来了如此巨大的恐慌，并且需要我们进行颠覆性的反思，主要事实大致有三：

OpenAI实现了原本被（特别是国内科技公司）认为不具有实用价值的超大模型的直接部署上线，即便是调用一次赔一次；

OpenAI做到了无比纯粹的劳务剥削，并以此获得了不可估量的训练数据，而且通过先发制人的（且调用一次赔一次）策略获得了更加不可估量的用户反馈数据；

OpenAI证明了只要东西做得足够好，那么它就可以足够烂（开源数据集，或者上述的I与II），而不需要有一个特定的产品方法论。

当然这个事实列表想列的话可以列上百条，这就仿佛沙漠风暴行动打醒了某个东亚大型行政组织一样。但是这不是今天的主题，所以但凡读者们想友善地发表意见，就请随意去友善。话锋转回这次的主题，我将会分三点来讨论为什么焦虑感是没有必要的（或者我不能为大家提供焦虑感是必要的论证）。

**一、无论你焦虑与否，你现在都没有什么办法解决它**

于个人来说，朋友圈中盛传了某大佬的在LLM时代你的Dos跟Donts，具体不再冗述，我对其评价为消极想法中的积极思考，也就是说，到底你也做不了什么，做好你自己的事情才是对的。

当然，我更想讲的其实是组织层面上的事情。于个人即便你再去做好一些自己的事情，但是你如果真的有那个心气去解决它，那还是不得不去寻找一个组织来实现。不幸的是，我当下对国内的组织有着极端悲观的看法，换句话说，大家看似很卷，但是到头来恐怕也没人能做出什么真正让西方望其项背的东西。就我的理解，国内的组织想要在目前已经大幅落后的情况下，基本只是做出能与GPT比肩的东西，就只有两个模式可以选，而且这两个模式不是艳红（劣币驱逐良币）模式或者慧文（瓦岗军）模式，而是MBS模式或者慈父模式。

MBS（Mohammed bin Salman）模式就是指无止境的投入，硬件直接从买地盖核电站开始投入，软件上直接用钱把openAI的核心成员全部挖来，如果做不到那就用钱把国内的大佬们成批的挖过来，所有人都带着最厉害的博士都上一线直接干活儿，最后再盖一座数据工厂浮士德，全年无休无止的产生数据。然后以上所有的都直接乘三，按照曼哈顿计划做多分备份，举整个财阀之力去支撑起这个工程，几千万刀就不要看了，至少按照微软的100亿刀起步。不然呢？

慈父（Ио́сиф Виссарио́нович Ста́лин）模式则对应的，如果你没有无穷无尽的预算，那么干脆找一群不问出身的年轻人，在西伯利亚（OK，罗布泊）的荒野盖起一座城，给这些年轻人解决生活上的一切问题，让他们自由的发挥，缓慢而踏实的培养一批有真才实干的人，剔除掉目前学术界的浮躁，争取在5～10年的时间内，从基础到工程形成一套完整知识体系，再去与西方一决雌雄。

**二、LLM本身可能也不是实现强AGI的可行途径**

我们在这里不再反复讨论什么是强人工智能，当然我还是忍不住扯一句，如果仅以“能像一般人类一样进行对话“作为标准，那GPT4何止强人工智能，简直是现世神了。你让它去写个促进国内某行政区划的大模型产业的白皮书，那效果怕是好过我们行政组织里面一般人类的很多倍。这里我的主要观点，在于语言本身的特性，按照层次可以用以下三段总结：

作为真实世界的表象，语言本身具有模糊性，对同一语言所产生的思想与同一思想所产生的输出均不一样。这里举个简单的例子，比如你的孩子考试考了60分，你面色平静地讲到“考的真不错”，孩子听了后欢欣鼓舞问你可不可以奖励他氪两单，于是你奖励了他一顿羊驼狂奔。

正因为模糊性，人生来就对语言的使用就具有偏见性，从而个体对语言所关联的思想才具有一致性，而通过大量数据所学习而来的LLM有可能失去这种偏见性。接着上面的例子，比如60分的时候我们认为这句话是在说反话，那么提高到多少分的时候才不是反话？这并没有一个确定的标准，而遵从人内心对世界的理解本身的偏见性。换句话说，一个人喜欢讲“考得真不错”，可能只是因为他就是喜欢用这句话来做讽刺，而与到底考了多少分没有任何关系。而大数据自然而然地，会抹杀这种偏见性，一个LLM可能会学到一个基于分数的正态分布，我们按照采样来决定这句话到底是鼓励还是嘲讽。

一旦失去偏见性，那么LLM便不能基于某一个思想而创造新的知识或者概念，这便脱离了强人工智能的定义。换句话说，基于语言的新知识或者新概念，实质上是一种旧知识或者旧概念与偏见性结合出来的产物。就好像“翔”这个字在几年前还单纯的是一个翔的含义，而基于了某个个体的语言偏见性，以及这种偏见性本身带来的戏剧效果，才导致出现并传播了当下这个意思。

**三、焦虑本身是即是你之存在**

焦虑本身并非一个具有负面意义的概念，人会否定焦虑之价值更多原因只是世俗性的偏见。从生理角度来讲，焦虑是一种对预期的不确定性（通常是对可能出现的负面结果）所导致的情绪上的动荡与不愉快的感觉，是一种作为人类的极端的正常的反应。区分于焦虑所形成的disorder，适度的焦虑是推动人类自我进步的一个条件。所以不妨干了这碗焦虑鸡汤，通宵再战它一年的NaN。

从海德格尔的存在主义哲学层面来讲，我认为LLM带给我的，与其称之为焦虑，不如说它就是一种具象化的Angst（畏），即是此在的存在自身。虽然LLM带给我的不是无法回避的死亡（当然LLM确实带给很多人了社会性死亡），而是一种对智慧的源生的追求，如果我没有走在探寻智慧的路上，那其实我已经死了。

以上，希望大家可以喜欢。
